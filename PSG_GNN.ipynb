{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f5f33d",
   "metadata": {},
   "source": [
    "# Patient Similarity Graph Using GNN (SAGEConv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6f2e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "use_cuda_if_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e974542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropping_cols(df, p=80):\n",
    "    #1- count the number of NaN values in each column\n",
    "    #2- calculate the percentage of NaN values in each column\n",
    "    #3- get the list of columns to drop\n",
    "    #4- drop the columns with more than 80% NaN values\n",
    "    nan_counts = df.isna().sum()    \n",
    "    nan_percentages = nan_counts / len(df) * 100 \n",
    "    cols_to_drop = nan_percentages[nan_percentages > p].index.tolist()\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd87745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(n, tr=0.8, vl=0.1, ts=0.1):\n",
    "    import random\n",
    "    train_size = int(n * tr)\n",
    "    val_size = int(n * vl)\n",
    "    test_size = int(n * ts)\n",
    "\n",
    "    # Initialize the three lists\n",
    "    train_list = torch.zeros(n, dtype=torch.bool)\n",
    "    val_list   = torch.zeros(n, dtype=torch.bool)\n",
    "    test_list  = torch.zeros(n, dtype=torch.bool)\n",
    "\n",
    "    indices = [i for i in range(n)]\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    for i in range(n):\n",
    "        j = indices[i]\n",
    "        if i <train_size:\n",
    "            train_list[j] = torch.tensor(True)\n",
    "        elif i>= train_size and i< train_size + val_size:\n",
    "            val_list[j] = torch.tensor(True)\n",
    "        elif i>=train_size + val_size:\n",
    "            test_list[j] = torch.tensor(True)\n",
    "    return train_list, val_list, test_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335632e",
   "metadata": {},
   "source": [
    "# Reading Lung dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6411856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\VCU 2023\\PSN Patient Similarity Network\\GraphAugmentation'\n",
    "original_lung = pd.read_csv(f'{path}/data/Lung/numerical.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26dad6d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F1', 'F2', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F12', 'F13', 'F16', 'F18', 'F19', 'F23', 'F24']\n"
     ]
    }
   ],
   "source": [
    "original_features = list(original_lung.columns)\n",
    "\n",
    "new_features      = [f'F{i}' for i in range(len(original_features))]\n",
    "features_dict     = {new_features[i]: list(original_features)[i] for i in range(len(original_features))}\n",
    "\n",
    "Lung = original_lung\n",
    "Lung = Lung.rename(columns=dict(zip(original_features, new_features)))\n",
    "Lung = dropping_cols(Lung)\n",
    "\n",
    "# Imputing the NaN values to the mean\n",
    "features_to_impute = [i for i in list(Lung.columns) if i not in ['F11', 'F20','F21','F22']]\n",
    "print(features_to_impute)\n",
    "Lung[features_to_impute] = Lung[features_to_impute].fillna(Lung[features_to_impute].mean())\n",
    "Lung.to_csv('data/raw/Lung.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c71ecf",
   "metadata": {},
   "source": [
    "### 1- creting the data.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a8d71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([773, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmad Al Musawi\\AppData\\Local\\Temp\\ipykernel_18156\\2173150290.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  temp.append(torch.tensor(col))\n"
     ]
    }
   ],
   "source": [
    "df = Lung[features_to_impute]\n",
    "# df = df.mul(100).round().astype(int)\n",
    "X = torch.tensor(df.values)\n",
    "\n",
    "num_classes  = X.shape[0]\n",
    "num_features = X.shape[1]\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "tensors = []\n",
    "for row in X:\n",
    "    temp = []\n",
    "    for col in row:\n",
    "        temp.append(torch.tensor(col))\n",
    "    tensors.append(torch.tensor(temp))\n",
    "\n",
    "X = torch.stack(tensors)\n",
    "X[0]\n",
    "X = X.to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c8a2ff",
   "metadata": {},
   "source": [
    "### 2- Creating data.edge_index\n",
    "+ finding the similarity matrix SM of the given datafram \n",
    "+ convert the similarity matrix to edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c553de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.05329222, 0.0433273 , ..., 0.06245797, 0.03531149,\n",
       "        0.01812901],\n",
       "       [0.05329222, 1.        , 0.08696928, ..., 0.03601998, 0.03862114,\n",
       "        0.02235329],\n",
       "       [0.0433273 , 0.08696928, 1.        , ..., 0.03296819, 0.04786752,\n",
       "        0.02156027],\n",
       "       ...,\n",
       "       [0.06245797, 0.03601998, 0.03296819, ..., 1.        , 0.02779196,\n",
       "        0.01518994],\n",
       "       [0.03531149, 0.03862114, 0.04786752, ..., 0.02779196, 1.        ,\n",
       "        0.02041917],\n",
       "       [0.01812901, 0.02235329, 0.02156027, ..., 0.01518994, 0.02041917,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SM = pd.DataFrame(1/(1 + squareform(pdist(df, 'euclidean'))), index=df.index, columns=df.index).values\n",
    "SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7268e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 597529,\n",
       " 0.01: 588741,\n",
       " 0.02: 422043,\n",
       " 0.03: 249035,\n",
       " 0.04: 144331,\n",
       " 0.05: 83351,\n",
       " 0.06: 53701,\n",
       " 0.07: 39019,\n",
       " 0.08: 29933,\n",
       " 0.09: 24539,\n",
       " 0.1: 21083,\n",
       " 0.11: 18783,\n",
       " 0.12: 16783,\n",
       " 0.13: 14619,\n",
       " 0.14: 13303,\n",
       " 0.15: 11743,\n",
       " 0.16: 10841,\n",
       " 0.17: 9487,\n",
       " 0.18: 8849,\n",
       " 0.19: 8119,\n",
       " 0.2: 6835,\n",
       " 0.21: 6715,\n",
       " 0.22: 5865,\n",
       " 0.23: 5685,\n",
       " 0.24: 5373,\n",
       " 0.25: 4489,\n",
       " 0.26: 4485,\n",
       " 0.27: 3827,\n",
       " 0.28: 3789,\n",
       " 0.29: 3415,\n",
       " 0.3: 3415,\n",
       " 0.31: 2791,\n",
       " 0.32: 2791,\n",
       " 0.33: 2791,\n",
       " 0.34: 2467,\n",
       " 0.35: 2467,\n",
       " 0.36: 2465,\n",
       " 0.37: 2229,\n",
       " 0.38: 2229,\n",
       " 0.39: 2229,\n",
       " 0.4: 2229,\n",
       " 0.41: 2229,\n",
       " 0.42: 1523,\n",
       " 0.43: 1523,\n",
       " 0.44: 1523,\n",
       " 0.45: 1523,\n",
       " 0.46: 1523,\n",
       " 0.47: 1523,\n",
       " 0.48: 1523,\n",
       " 0.49: 1523}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_edge_index(SM, th=0):\n",
    "    '''\n",
    "    SM: similarity matrix,\n",
    "    th: threshold for edge weight,\n",
    "    return edge_index'''\n",
    "    source = []\n",
    "    target = []\n",
    "    weight = []\n",
    "    for i in range(SM.shape[0]):\n",
    "        for j in range(SM.shape[1]):\n",
    "            if SM[i,j]> th:\n",
    "                source.append(i)\n",
    "                target.append(j)\n",
    "                weight.append(SM[i,j])\n",
    "\n",
    "    return torch.tensor([source, target])\n",
    "\n",
    "edge_index = get_edge_index(SM)\n",
    "total_edge = {t/100: get_edge_index(SM, t/100).shape[1] for t in range(0, 50)}\n",
    "total_edge    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a9c61d",
   "metadata": {},
   "source": [
    "### 3- Creating data.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3f5de11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([773])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = {'NSCLC'        : 0,\n",
    "     'NSCLC Surgery': 1,\n",
    "     'SCLC'         : 2}\n",
    "Y = torch.tensor([v[i] for i in list(Lung['F22'])])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a1509",
   "metadata": {},
   "source": [
    "### 4- Creating the different masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a3c1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mask, v_mask, ts_mask = split_mask(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a712b8f",
   "metadata": {},
   "source": [
    "### 5- Creating the data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6189665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[773, 15], edge_index=[2, 597529], y=[773], train_mask=[773], val_mask=[773], test_mask=[773])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=X, edge_index = edge_index, y = Y, train_mask = tr_mask, val_mask = v_mask, test_mask = ts_mask)\n",
    "\n",
    "print(num_features,num_classes,)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba58b7a",
   "metadata": {},
   "source": [
    "# GNN section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d30ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = SAGEConv(num_features,\n",
    "                             num_classes,\n",
    "                             aggr=\"max\") # max, mean, add ...)\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.conv(data.x, data.edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "18f94431",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda_if_available else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20712eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "43e42e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9d5bea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Val: 0.5913, Test: 0.6667\n",
      "Epoch: 020, Val: 0.6348, Test: 0.6667\n",
      "Epoch: 030, Val: 0.6348, Test: 0.6667\n",
      "Epoch: 040, Val: 0.6348, Test: 0.6667\n",
      "Epoch: 050, Val: 0.6348, Test: 0.6667\n",
      "Epoch: 060, Val: 0.6348, Test: 0.6667\n",
      "Epoch: 070, Val: 0.6609, Test: 0.6752\n",
      "Epoch: 080, Val: 0.6609, Test: 0.6752\n",
      "Epoch: 090, Val: 0.6609, Test: 0.6752\n",
      "Epoch: 100, Val: 0.6609, Test: 0.6752\n",
      "Epoch: 110, Val: 0.6696, Test: 0.6752\n",
      "Epoch: 120, Val: 0.6696, Test: 0.6752\n",
      "Epoch: 130, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 140, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 150, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 160, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 170, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 180, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 190, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 200, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 210, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 220, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 230, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 240, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 250, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 260, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 270, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 280, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 290, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 300, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 310, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 320, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 330, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 340, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 350, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 360, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 370, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 380, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 390, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 400, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 410, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 420, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 430, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 440, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 450, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 460, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 470, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 480, Val: 0.6783, Test: 0.6838\n",
      "Epoch: 490, Val: 0.6783, Test: 0.6838\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1,500):\n",
    "    train()\n",
    "    _, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    log = 'Epoch: {:03d}, Val: {:.4f}, Test: {:.4f}'\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(log.format(epoch, best_val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e2e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32ab4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Test Acc: 0.6869\n",
      "Epoch: 020, Test Acc: 0.7076\n",
      "Epoch: 030, Test Acc: 0.7076\n",
      "Epoch: 040, Test Acc: 0.7076\n",
      "Epoch: 050, Test Acc: 0.7076\n",
      "Epoch: 060, Test Acc: 0.7076\n",
      "Epoch: 070, Test Acc: 0.7076\n",
      "Epoch: 080, Test Acc: 0.7076\n",
      "Epoch: 090, Test Acc: 0.7076\n",
      "Epoch: 100, Test Acc: 0.7089\n",
      "Epoch: 110, Test Acc: 0.7089\n",
      "Epoch: 120, Test Acc: 0.7089\n",
      "Epoch: 130, Test Acc: 0.7089\n",
      "Epoch: 140, Test Acc: 0.7089\n",
      "Epoch: 150, Test Acc: 0.7089\n",
      "Epoch: 160, Test Acc: 0.7089\n",
      "Epoch: 170, Test Acc: 0.7089\n",
      "Epoch: 180, Test Acc: 0.7089\n",
      "Epoch: 190, Test Acc: 0.7089\n",
      "Epoch: 200, Test Acc: 0.7089\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, ReLU\n",
    "from torch_geometric.nn import SAGEConv\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the dataset\n",
    "# dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "# Define the model\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_features, 16)\n",
    "        self.conv2 = SAGEConv(16, num_classes)\n",
    "        self.lin1 = Linear(num_classes, 32)\n",
    "        self.lin2 = Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the model and define the optimizer\n",
    "model = Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = pred.eq(data.y).sum().item() / len(data.y)\n",
    "    return acc\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f'Epoch: {epoch:03d}, Test Acc: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be717858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c42b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
