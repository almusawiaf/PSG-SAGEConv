{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5f5f33d",
   "metadata": {},
   "source": [
    "# Patient Similarity Graph Using GNN (SAGEConv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6f2e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "use_cuda_if_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e974542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropping_cols(df, p=80):\n",
    "    #1- count the number of NaN values in each column\n",
    "    #2- calculate the percentage of NaN values in each column\n",
    "    #3- get the list of columns to drop\n",
    "    #4- drop the columns with more than 80% NaN values\n",
    "    nan_counts = df.isna().sum()    \n",
    "    nan_percentages = nan_counts / len(df) * 100 \n",
    "    cols_to_drop = nan_percentages[nan_percentages > p].index.tolist()\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bd87745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(n, tr=0.8, vl=0.1, ts=0.1):\n",
    "    import random\n",
    "    train_size = int(n * tr)\n",
    "    val_size = int(n * vl)\n",
    "    test_size = int(n * ts)\n",
    "\n",
    "    # Initialize the three lists\n",
    "    train_list = torch.zeros(n, dtype=torch.bool)\n",
    "    val_list   = torch.zeros(n, dtype=torch.bool)\n",
    "    test_list  = torch.zeros(n, dtype=torch.bool)\n",
    "\n",
    "    indices = [i for i in range(n)]\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    for i in range(n):\n",
    "        j = indices[i]\n",
    "        if i <train_size:\n",
    "            train_list[j] = torch.tensor(True)\n",
    "        elif i>= train_size and i< train_size + val_size:\n",
    "            val_list[j] = torch.tensor(True)\n",
    "        elif i>=train_size + val_size:\n",
    "            test_list[j] = torch.tensor(True)\n",
    "    return train_list, val_list, test_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8335632e",
   "metadata": {},
   "source": [
    "# Reading Lung dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6411856e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "      <th>770</th>\n",
       "      <th>771</th>\n",
       "      <th>772</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.060756</td>\n",
       "      <td>0.066758</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.042997</td>\n",
       "      <td>0.040514</td>\n",
       "      <td>0.040044</td>\n",
       "      <td>0.022366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>0.022181</td>\n",
       "      <td>0.020940</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.042610</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>0.024892</td>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.040040</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.038621</td>\n",
       "      <td>0.022353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060756</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046873</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.020304</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>0.026645</td>\n",
       "      <td>0.038336</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.041972</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>0.047868</td>\n",
       "      <td>0.021560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066758</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.046873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.026898</td>\n",
       "      <td>0.024809</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.020909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042584</td>\n",
       "      <td>0.034927</td>\n",
       "      <td>0.055312</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>0.028199</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>0.033631</td>\n",
       "      <td>0.023815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>0.037098</td>\n",
       "      <td>0.024252</td>\n",
       "      <td>0.128447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.027069</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>0.032260</td>\n",
       "      <td>0.019099</td>\n",
       "      <td>0.011011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.017640</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017803</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>0.032185</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>0.038760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.042997</td>\n",
       "      <td>0.040040</td>\n",
       "      <td>0.041972</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>0.024101</td>\n",
       "      <td>0.022483</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.031129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>0.027404</td>\n",
       "      <td>0.050762</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068583</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0.040514</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>0.032260</td>\n",
       "      <td>0.017813</td>\n",
       "      <td>0.032664</td>\n",
       "      <td>0.029854</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028098</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.024953</td>\n",
       "      <td>0.065419</td>\n",
       "      <td>0.041969</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.068583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>0.015190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>0.040044</td>\n",
       "      <td>0.038621</td>\n",
       "      <td>0.047868</td>\n",
       "      <td>0.033631</td>\n",
       "      <td>0.019099</td>\n",
       "      <td>0.017147</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.017122</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>0.020941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.036738</td>\n",
       "      <td>0.034172</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.022366</td>\n",
       "      <td>0.022353</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.024565</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.017217</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.000000  0.090335  0.060756  0.066758  0.020480  0.025235  0.023735   \n",
       "1    0.090335  1.000000  0.086969  0.058750  0.020027  0.024279  0.022181   \n",
       "2    0.060756  0.086969  1.000000  0.046873  0.020022  0.020304  0.020201   \n",
       "3    0.066758  0.058750  0.046873  1.000000  0.019342  0.026898  0.024809   \n",
       "4    0.020480  0.020027  0.020022  0.019342  1.000000  0.012786  0.033449   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "768  0.023787  0.024673  0.026778  0.023123  0.011824  0.017640  0.012386   \n",
       "769  0.042997  0.040040  0.041972  0.034828  0.027106  0.016680  0.024101   \n",
       "770  0.040514  0.036020  0.032968  0.035649  0.032260  0.017813  0.032664   \n",
       "771  0.040044  0.038621  0.047868  0.033631  0.019099  0.017147  0.018925   \n",
       "772  0.022366  0.022353  0.021560  0.023815  0.011011  0.024565  0.012676   \n",
       "\n",
       "            7         8         9  ...       763       764       765  \\\n",
       "0    0.021992  0.018617  0.022272  ...  0.042391  0.037341  0.046716   \n",
       "1    0.020940  0.019407  0.021587  ...  0.035784  0.031703  0.042610   \n",
       "2    0.019231  0.021851  0.021909  ...  0.027387  0.026645  0.038336   \n",
       "3    0.021157  0.016758  0.020909  ...  0.042584  0.034927  0.055312   \n",
       "4    0.037098  0.024252  0.128447  ...  0.017585  0.027069  0.015457   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "768  0.011649  0.013947  0.012555  ...  0.017803  0.014956  0.032185   \n",
       "769  0.022483  0.027470  0.031129  ...  0.024074  0.030682  0.027404   \n",
       "770  0.029854  0.022677  0.036845  ...  0.028098  0.042989  0.024953   \n",
       "771  0.017122  0.021868  0.020941  ...  0.022329  0.023668  0.036738   \n",
       "772  0.011689  0.011354  0.011555  ...  0.020783  0.015441  0.034978   \n",
       "\n",
       "          766       767       768       769       770       771       772  \n",
       "0    0.061183  0.027825  0.023787  0.042997  0.040514  0.040044  0.022366  \n",
       "1    0.047615  0.024892  0.024673  0.040040  0.036020  0.038621  0.022353  \n",
       "2    0.040296  0.022389  0.026778  0.041972  0.032968  0.047868  0.021560  \n",
       "3    0.047133  0.028199  0.023123  0.034828  0.035649  0.033631  0.023815  \n",
       "4    0.028169  0.033440  0.011824  0.027106  0.032260  0.019099  0.011011  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "768  0.017983  0.013271  1.000000  0.019088  0.016411  0.026172  0.038760  \n",
       "769  0.050762  0.028216  0.019088  1.000000  0.068583  0.037675  0.016200  \n",
       "770  0.065419  0.041969  0.016411  0.068583  1.000000  0.027792  0.015190  \n",
       "771  0.034172  0.020588  0.026172  0.037675  0.027792  1.000000  0.020419  \n",
       "772  0.017217  0.013486  0.038760  0.016200  0.015190  0.020419  1.000000  \n",
       "\n",
       "[773 rows x 773 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = pd.read_csv('data/Lung/SM/numericalSM.csv')\n",
    "cdf = pd.read_csv('data/Lung/SM/categoricalSM.csv')\n",
    "original_lung = pd.read_csv(f'data/raw/numerical.csv', index_col=0)\n",
    "ndf = ndf.loc[:, ~ndf.columns.str.contains('^Unnamed')]\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26dad6d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_features = list(original_lung.columns)\n",
    "\n",
    "new_features      = [f'F{i}' for i in range(len(original_features))]\n",
    "features_dict     = {new_features[i]: list(original_features)[i] for i in range(len(original_features))}\n",
    "\n",
    "Lung = original_lung\n",
    "Lung = Lung.rename(columns=dict(zip(original_features, new_features)))\n",
    "Lung = dropping_cols(Lung, 30)\n",
    "\n",
    "# Imputing the NaN values to the mean\n",
    "features_to_impute = [i for i in list(Lung.columns) if i not in ['F11', 'F20','F21','F22']]\n",
    "# print(features_to_impute)\n",
    "# Lung[features_to_impute] = Lung[features_to_impute].fillna(Lung[features_to_impute].mean())\n",
    "Lung[features_to_impute] = Lung[features_to_impute].fillna(0)\n",
    "# Lung.to_csv('data/raw/Lung.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c71ecf",
   "metadata": {},
   "source": [
    "### 1- creting the data.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a8d71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([773, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8857/2520106884.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  temp.append(torch.tensor(col))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  8.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 6.6777,  9.0000, 14.4877,  ...,  6.0000, 28.1263, 47.1238],\n",
       "        [ 4.9350, 10.0000, 16.5692,  ...,  6.0000, 30.1369, 47.8001],\n",
       "        ...,\n",
       "        [ 6.8261,  6.0000, 16.6087,  ...,  0.0000, 27.1005, 59.5701],\n",
       "        [ 3.5907,  6.0000, 12.3849,  ...,  0.0000, 22.7197, 43.9183],\n",
       "        [ 2.7957, 10.0000,  8.1896,  ...,  0.0000, 15.4346, 27.1226]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Lung[features_to_impute]\n",
    "# df = df.mul(100).round().astype(int)\n",
    "X = torch.tensor(df.values)\n",
    "\n",
    "num_classes  = 3\n",
    "num_features = X.shape[1]\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "tensors = []\n",
    "for row in X:\n",
    "    temp = []\n",
    "    for col in row:\n",
    "        temp.append(torch.tensor(col))\n",
    "    tensors.append(torch.tensor(temp))\n",
    "\n",
    "X = torch.stack(tensors)\n",
    "X[0]\n",
    "X = X.to(torch.float32)\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25c8a2ff",
   "metadata": {},
   "source": [
    "### 2- Creating data.edge_index\n",
    "+ finding the similarity matrix SM of the given datafram \n",
    "+ convert the similarity matrix to edge_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14280eb4",
   "metadata": {},
   "source": [
    "## Finding the similarity matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0484635",
   "metadata": {},
   "source": [
    "SM = pd.DataFrame(1/(1 + squareform(pdist(df, 'euclidean'))), index=df.index, columns=df.index).values\n",
    "SM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8daf1856",
   "metadata": {},
   "source": [
    "def sim(X, Y):\n",
    "    t, s = 0, 0\n",
    "    for i in range(len(X)):\n",
    "        if X[i] !=0 and Y[i] !=0:\n",
    "            t=t+1\n",
    "            s = s + (X[i]-Y[i])**2\n",
    "    return  (1-s**0.5) * t/len(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eeb0299d",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df))\n",
    "df_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50c7d44a",
   "metadata": {},
   "source": [
    "SM = df_scaled.apply(lambda row1: df_scaled.apply(lambda row2: sim(row1, row2), axis=1), axis=1)\n",
    "\n",
    "print(SM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7268e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    1.000000  0.983531  0.982876  0.988837  0.985420  0.991438  0.986194   \n",
      "1    0.983531  1.000000  0.954059  0.929891  0.785871  0.824140  0.807090   \n",
      "2    0.982876  0.954059  1.000000  0.911016  0.785817  0.788856  0.787753   \n",
      "3    0.988837  0.929891  0.911016  1.000000  0.778127  0.841688  0.827989   \n",
      "4    0.985420  0.785871  0.785817  0.778127  1.000000  0.662131  0.873549   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "768  0.758758  0.422124  0.426145  0.418457  0.338359  0.397169  0.347487   \n",
      "769  0.691575  0.287695  0.288418  0.285103  0.278168  0.249720  0.273522   \n",
      "770  0.684061  0.268523  0.266639  0.268320  0.266123  0.238712  0.266421   \n",
      "771  0.684061  0.269789  0.272732  0.267092  0.243789  0.235632  0.243163   \n",
      "772  0.638119  0.151080  0.149427  0.153707  0.084288  0.154879  0.105457   \n",
      "\n",
      "            7         8         9  ...       763       764       765  \\\n",
      "0    0.985294  0.986194  0.988674  ...  0.858301  0.852459  0.846756   \n",
      "1    0.795395  0.778885  0.801664  ...  0.655376  0.637508  0.777678   \n",
      "2    0.776829  0.804111  0.804638  ...  0.640816  0.627051  0.778682   \n",
      "3    0.797538  0.743244  0.795089  ...  0.661559  0.642010  0.778711   \n",
      "4    0.886419  0.823938  0.970307  ...  0.594258  0.628146  0.768302   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "768  0.335265  0.367753  0.350025  ...  0.668236  0.640771  0.854047   \n",
      "769  0.270226  0.278630  0.282419  ...  0.579987  0.607278  0.777503   \n",
      "770  0.264089  0.253736  0.268954  ...  0.573986  0.602781  0.762057   \n",
      "771  0.235510  0.251899  0.249533  ...  0.558087  0.574702  0.766236   \n",
      "772  0.093946  0.089387  0.092162  ...  0.456162  0.436023  0.699384   \n",
      "\n",
      "          766       767       768       769       770       771       772  \n",
      "0    0.819996  0.785567  0.758758  0.691575  0.684061  0.684061  0.638119  \n",
      "1    0.819204  0.784953  0.422124  0.287695  0.268523  0.269789  0.151080  \n",
      "2    0.819102  0.784919  0.426145  0.288418  0.266639  0.272732  0.149427  \n",
      "3    0.819610  0.785294  0.418457  0.285103  0.268320  0.267092  0.153707  \n",
      "4    0.819325  0.785106  0.338359  0.278168  0.266123  0.243789  0.084288  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "768  0.938438  0.973129  1.000000  0.727918  0.687094  0.764124  0.703721  \n",
      "769  0.871443  0.905392  0.727918  1.000000  0.938046  0.886864  0.707359  \n",
      "770  0.864016  0.898297  0.687094  0.938046  1.000000  0.846920  0.697475  \n",
      "771  0.864016  0.898297  0.764124  0.886864  0.846920  1.000000  0.765262  \n",
      "772  0.817921  0.852521  0.703721  0.707359  0.697475  0.765262  1.000000  \n",
      "\n",
      "[773 rows x 773 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 113833])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_edge_index(SM, th=0):\n",
    "    '''\n",
    "    SM: similarity matrix,\n",
    "    th: threshold for edge weight,\n",
    "    return edge_index'''\n",
    "    source = []\n",
    "    target = []\n",
    "    weight = []\n",
    "    for i in range(SM.shape[0]):\n",
    "        for j in range(SM.shape[1]):\n",
    "            if SM[i,j]> th:\n",
    "                source.append(i)\n",
    "                target.append(j)\n",
    "                weight.append(SM[i,j])\n",
    "\n",
    "    return torch.tensor([source, target])\n",
    "\n",
    "SM = pd.read_csv('data/Lung/mySM/MySim.csv')\n",
    "print(SM)\n",
    "\n",
    "edge_index = get_edge_index(SM.values, 0.9)\n",
    "edge_index.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00a9c61d",
   "metadata": {},
   "source": [
    "### 3- Creating data.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3f5de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076326002587322\n",
      "0.08408796895213454\n",
      "0.20827943078913325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([773])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = {'NSCLC'        : 0,\n",
    "     'NSCLC Surgery': 1,\n",
    "     'SCLC'         : 2}\n",
    "Y = torch.tensor([v[i] for i in list(Lung['F22'])])\n",
    "\n",
    "print(list(Lung['F22']).count('NSCLC')/773)\n",
    "print(list(Lung['F22']).count('NSCLC Surgery')/773)\n",
    "print(list(Lung['F22']).count('SCLC')/773)\n",
    "\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a7a1509",
   "metadata": {},
   "source": [
    "### 4- Creating the different masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a3c1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mask, v_mask, ts_mask = split_mask(X.shape[0], 0.7, 0.1, 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a712b8f",
   "metadata": {},
   "source": [
    "### 5- Creating the data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6189665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[773, 15], edge_index=[2, 113833], y=[773], train_mask=[773], val_mask=[773], test_mask=[773])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=X, edge_index = edge_index, y = Y, train_mask = tr_mask, val_mask = v_mask, test_mask = ts_mask)\n",
    "\n",
    "print(num_features,num_classes,)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32ab4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 3\n",
      "GCN(\n",
      "  (conv1): GCNConv(15, 16)\n",
      "  (conv2): GCNConv(16, 3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "tr_mask, v_mask, ts_mask = split_mask(X.shape[0], 0.7, 0.1,0.2)\n",
    "data = Data(x=X, edge_index = edge_index, y = Y, train_mask = tr_mask, val_mask = v_mask, test_mask = ts_mask)\n",
    "\n",
    "print(num_features, num_classes)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize the model and define the optimizer\n",
    "# model = Net()\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
    "# # Train the model\n",
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     out = model(data.x, data.edge_index)\n",
    "#     loss = F.nll_loss(out, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# 50\n",
    "# # Evaluate the model\n",
    "# def test(mask):\n",
    "#     model.eval()\n",
    "#     out = model(data.x, data.edge_index)\n",
    "#     pred = out.argmax(dim=1)\n",
    "#     correct = pred[mask] == data.y[mask]\n",
    "#     acc = int(correct.sum()) / int(mask.sum())\n",
    "# #     acc = pred.eq(data.y).sum().item() / len(data.y)\n",
    "#     return acc\n",
    "\n",
    "\n",
    "# val_acc_all = []\n",
    "# test_acc_all = []\n",
    "# for epoch in range(1, 201):\n",
    "#     loss = train()\n",
    "#     val_acc = test(data.val_mask)\n",
    "#     test_acc = test(data.test_mask)\n",
    "#     val_acc_all.append(val_acc)\n",
    "#     test_acc_all.append(test_acc)\n",
    "#     if epoch%10 ==0:\n",
    "#         print(f'Epoch: {epoch:03d} Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be717858",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_acc_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(val_acc_all) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), val_acc_all, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation accuracy\u001b[39m\u001b[39m'\u001b[39m, c\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(test_acc_all) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), test_acc_all, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTesting accuracy\u001b[39m\u001b[39m'\u001b[39m, c\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_acc_all' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(np.arange(1, len(val_acc_all) + 1), val_acc_all, label='Validation accuracy', c='blue')\n",
    "plt.plot(np.arange(1, len(test_acc_all) + 1), test_acc_all, label='Testing accuracy', c='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accurarcy')\n",
    "plt.title('SAGEConv')\n",
    "plt.legend(loc='lower right', fontsize='x-large')\n",
    "plt.savefig('gat_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c42b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set\n",
      "F1 : 0.5278003246753247 \n",
      "confusion matrix: \n",
      "[[51  0  0]\n",
      " [ 6  0  0]\n",
      " [20  0  0]]\n",
      "\n",
      "Test set\n",
      "F1 : 0.6147809340394801 \n",
      "confusion matrix: \n",
      "[[113   0   0]\n",
      " [ 14   0   0]\n",
      " [ 28   0   0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "# Calculate confusion matrix and F1 score\n",
    "mask_val = data.val_mask\n",
    "mask_test = data.test_mask\n",
    "model.eval()\n",
    "\n",
    "out_val = model(data.x, data.edge_index)[mask_val].argmax(dim=1)\n",
    "out_test = model(data.x, data.edge_index)[mask_test].argmax(dim=1)\n",
    "y_true_val = data.y[mask_val]\n",
    "y_true_test = data.y[mask_test]\n",
    "\n",
    "confusion_matrix_val = confusion_matrix(y_true_val, out_val)\n",
    "confusion_matrix_test = confusion_matrix(y_true_test, out_test)\n",
    "f1_score_val = f1_score(y_true_val, out_val, average='weighted')\n",
    "f1_score_test = f1_score(y_true_test, out_test, average='weighted')\n",
    "\n",
    "print(f'Validation set\\nF1 : {f1_score_val} \\nconfusion matrix: \\n{confusion_matrix_val}\\n')\n",
    "print(f'Test set\\nF1 : {f1_score_test} \\nconfusion matrix: \\n{confusion_matrix_test}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc173b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Validation):\n",
      " [[51  0  0]\n",
      " [ 6  0  0]\n",
      " [20  0  0]]\n",
      "Confusion Matrix (Test):\n",
      " [[113   0   0]\n",
      " [ 14   0   0]\n",
      " [ 28   0   0]]\n",
      "\n",
      "F1 Score (Validation): 0.5278003246753247\n",
      "F1 Score (Test): 0.6147809340394801\n",
      "\n",
      "Precision (Validation): 0.4386911789509192\n",
      "Precision (Test): 0.5314880332986472\n",
      "\n",
      "Recall (Validation): 0.6623376623376623\n",
      "Recall (Test): 0.7290322580645161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/almusawiaf/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/almusawiaf/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate confusion matrix, F1 score, precision, recall, and ROAUC\n",
    "mask_val = data.val_mask\n",
    "mask_test = data.test_mask\n",
    "model.eval()\n",
    "\n",
    "out_val = model(data.x, data.edge_index)[mask_val].argmax(dim=1)\n",
    "out_test = model(data.x, data.edge_index)[mask_test].argmax(dim=1)\n",
    "y_true_val = data.y[mask_val]\n",
    "y_true_test = data.y[mask_test]\n",
    "\n",
    "confusion_matrix_val = confusion_matrix(y_true_val, out_val)\n",
    "confusion_matrix_test = confusion_matrix(y_true_test, out_test)\n",
    "f1_score_val = f1_score(y_true_val, out_val, average='weighted')\n",
    "f1_score_test = f1_score(y_true_test, out_test, average='weighted')\n",
    "precision_val = precision_score(y_true_val, out_val, average='weighted')\n",
    "precision_test = precision_score(y_true_test, out_test, average='weighted')\n",
    "recall_val = recall_score(y_true_val, out_val, average='weighted')\n",
    "recall_test = recall_score(y_true_test, out_test, average='weighted')\n",
    "\n",
    "# # ROAUC requires probability scores instead of predicted labels\n",
    "# out_val_probs = np.max(out_val.softmax(dim=0).detach().cpu().numpy(), axis=1)\n",
    "# out_test_probs = np.max(out_test.softmax(dim=0).detach().cpu().numpy(), axis=1)\n",
    "# roauc_val = roc_auc_score(y_true_val.cpu().numpy(), out_val_probs)\n",
    "# roauc_test = roc_auc_score(y_true_test.cpu().numpy(), out_test_probs)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix (Validation):\\n\", confusion_matrix_val)\n",
    "print(\"Confusion Matrix (Test):\\n\", confusion_matrix_test)\n",
    "print(\"\\nF1 Score (Validation):\", f1_score_val)\n",
    "print(\"F1 Score (Test):\", f1_score_test)\n",
    "print(\"\\nPrecision (Validation):\", precision_val)\n",
    "print(\"Precision (Test):\", precision_test)\n",
    "print(\"\\nRecall (Validation):\", recall_val)\n",
    "print(\"Recall (Test):\", recall_test)\n",
    "# print(\"ROAUC (Validation):\", roauc_val)\n",
    "# print(\"ROAUC (Test):\", roauc_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
